* Database testing for understanding performance

Databases are magic, and there's a lot of random theory out there
The purpose of this is to figure out what real world penalties there are from different types of data models

** For a traditional relational db, how does different data models affect performance
*** Setup structure
What type of computer do I have, how to send enough requests to cause the database to hang
*** Questions
+ How do different amounts of data + different number of columns
+ Join performance
+ How indexes impact performance
  
** For distributed databases, how do they handle traditional relational ideas
ACID: We mainly care about A: Atomicity (abortability) and Isolation (serialisable)

Atomicity Cases
+ Deadlock
+ Network fault
+ Constraint violation
+ Power failure

Isolation cases (act as if it have the whole database to itself) (from strongest to weak)
1. Serialisable
   a. No write skew
2. Snapshot isolation + Repeatable read
   a. No read skew (snapshot isolation)
   b. Repeatable read (sql server) lots of locks, but most use snapshot isolation (Multi version concurrency control)
   c. Snapshot isolation called "repeatable read" on postgres, and mysql, "shapshot" on mssql and "serializable" on oracle
3. Read commited
   a. No dirty reads
   b. No dirty writes
      a. Two processes set x=a, y=a and x=b, y=b should expect a or b but not both
   c. Default in Mysql, Postgres, SQL Server
4. Read uncommited

*** Read skew
Transfer $100 from X to Y
Decrement X by 100 and increment Y by 100
Then there's another process, get Y before commit = original, get X after commit = changed, meaning it doesn't sum up

Makes backups useless?
*** Write skew
Assume always 1 doctor oncall, first check num doctors on call, and if more than 1, then update doctor to be off
If two transactions run at once, they both check against old data, then they both run their transactions against old data and therefore violate an invariant
*** How to write Serializable
+ Two phase locking: lock whatever you read (conditional on rows), hold until commit / abort
  - Only stops writes
  - Big analytics query - lock whole database for writes
+ Serialisable Snapshot Isolation (SSI)
  - Used in postgres
  - Locks don't block, only record information, during commit phase determines whether there are conflicts
  - Optimistic approach (where 2PL is the pessimistic approach)
*** Cross DC transactions
+ Compensating transactions (abort/rollback at app level)
  Kind of like Atomicity
+ Apologies: after the fact detect and fix (discount codes etc), rather than preventing
  Kind of like Consistency
+ Implicit causal relationship of actions A then B
  - Eventual consistency: events arrive in any order, commutative and associative merges, monotonic logic
  - Causal: partial order of reads and writes, obeys "happened before" relation
  - Serialisable: Total order of transactions with conflicting reads and writes
